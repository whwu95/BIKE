<div align="center">

# ã€CVPR'2023ã€‘Bidirectional Cross-Modal Knowledge Exploration for Video Recognition with Pre-trained Vision-Language Models

[![Conference](http://img.shields.io/badge/CVPR-2023-6790AC.svg)](https://cvpr.thecvf.com/)
[![Paper](http://img.shields.io/badge/Paper-arxiv.2301.00182-b31b1b.svg)](https://arxiv.org/abs/2301.00182)
</div>


This is the official implementation of our **BIKE**: [Cross-Modal Knowledge Exploration for Video Recognition with Pre-trained Vision-Language Models](https://arxiv.org/abs/2301.00182).

Code will be available. Stay tuned.

## ğŸ“£ Updates
- [x] **[Feb 28, 2023]** ğŸ‰Our **BIKE** has been accepted by **CVPR-2023**.



## ğŸ“Œ Bibtex
If you find this repository useful, please starğŸŒŸ this repo and citeğŸ“‘ our paper:

```
@inproceedings{bike,
  title={Bidirectional Cross-Modal Knowledge Exploration for Video Recognition with Pre-trained Vision-Language Models},
  author={Wu, Wenhao and Wang, Xiaohan and Luo, Haipeng and Wang, Jingdong and Yang, Yi and Ouyang, Wanli},
  booktitle=CVPR,
  year={2023}
}
```
